{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from Bio.SeqIO import QualityIO\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import gzip\n",
    "\n",
    "from utils import dna_rev_comp, translate_dna2aa, convert_phred_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"acrdms_data_v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_a4 = \"MNINDLIREIKNKDYTVKLSGTDSNSITQLIIRVNNDGNEYVISESENESIVEKFISAFKNGWNQEYEDEEEFYNDMQTITLKSELN\"\n",
    "gt_a5 = \"MAYGKSRYNSYRKRSFNRSNKQRREYAQEMDRLEKAFENLDGWYLSSMKDSAYKDFGKYEIRLSNHSADNKYHDLENGRLIVNIKASKLNFVDIIENKLDKIIEKIDKLDLDKYRFINATNLEHDIKCYYKGFKTKKEVI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sequences(file_1, file_2, min_overlap=50, max_overlap=250, quality_threshold=0):\n",
    "    sequences = []\n",
    "    qualities = []\n",
    "    a_sequences = []\n",
    "    b_sequences = []\n",
    "\n",
    "    with gzip.open(file_1, \"rt\") as a_file, gzip.open(file_2, \"rt\") as b_file:\n",
    "        a_reader = QualityIO.FastqGeneralIterator(a_file)\n",
    "        b_reader = QualityIO.FastqGeneralIterator(b_file)\n",
    "        for total_read, (a, b) in enumerate(zip(a_reader, b_reader)):\n",
    "            a_id, a_seq, a_qual = a\n",
    "            a_qual = convert_phred_byte(bytes(a_qual, \"utf-8\"))\n",
    "            b_id, b_seq, b_qual = b\n",
    "            b_inv_qual = convert_phred_byte(bytes(b_qual[::-1], \"utf-8\"))\n",
    "            if len(a_seq) < 250:\n",
    "                a_seq = a_seq + \"G\"\n",
    "            if len(b_seq) < 250:\n",
    "                b_seq = b_seq + \"G\"\n",
    "            a_sequences.append(a_seq)\n",
    "            b_sequences.append(b_seq)\n",
    "            b_inv = dna_rev_comp(b_seq)\n",
    "            for expected_overlap in range(min_overlap, max_overlap):\n",
    "                if expected_overlap == 0 or a_seq[-expected_overlap:] == b_inv[:expected_overlap]:\n",
    "                    res_seq = a_seq + b_inv[expected_overlap:]\n",
    "                    res_qual = np.concatenate((\n",
    "                        a_qual[:-expected_overlap],\n",
    "                        np.minimum(a_qual[-expected_overlap:], b_inv_qual[:expected_overlap]),\n",
    "                        b_inv_qual[expected_overlap:]\n",
    "                    ), axis=0)\n",
    "                    if (res_qual < quality_threshold).any():\n",
    "                        break\n",
    "                    sequences.append(res_seq)\n",
    "                    break\n",
    "        print(\"total reads\", total_read)\n",
    "    return sequences\n",
    "\n",
    "def gather_variants(sequences, catch, gt):\n",
    "    count = 0\n",
    "    translations = {}\n",
    "    multiples = []\n",
    "    stops = []\n",
    "    mislengths = []\n",
    "    wildtype = 0\n",
    "\n",
    "    length = 3 * len(gt)\n",
    "    peptide_length = len(gt)\n",
    "    catch_length = len(catch)\n",
    "    synonymous = {}\n",
    "    \n",
    "    dist = np.zeros((length, 4))\n",
    "\n",
    "    for sequence in sequences:\n",
    "        tr = None\n",
    "        if catch in sequence:\n",
    "            index = sequence.index(catch) + catch_length\n",
    "            gene = sequence[index:index + length]\n",
    "            tr = translate_dna2aa(gene)\n",
    "            count += 1\n",
    "        if catch in dna_rev_comp(sequence):\n",
    "            sequence = dna_rev_comp(sequence)\n",
    "            index = sequence.index(catch) + catch_length\n",
    "            gene = sequence[index:index + length]\n",
    "            tr = translate_dna2aa(gene)\n",
    "            count += 1\n",
    "        if tr is not None:\n",
    "            if len(tr) != peptide_length:\n",
    "                mislengths.append(tr)\n",
    "                continue\n",
    "            if tr == gt:\n",
    "                wildtype += 1\n",
    "                if gene not in synonymous:\n",
    "                    synonymous[gene] = 0\n",
    "                synonymous[gene] += 1\n",
    "            if (np.array([c for c in tr]) != np.array([c for c in gt])).sum() > 1:\n",
    "                multiples.append(tr)\n",
    "                continue\n",
    "            if \"*\" in tr:\n",
    "                stops.append(tr)\n",
    "                # continue\n",
    "            for idx, val in enumerate(gene):\n",
    "                if tr[idx // 3] != gt[idx // 3]:\n",
    "                    dist[idx, \"GATC\".index(val)] += 1\n",
    "            if tr not in translations:\n",
    "                translations[tr] = 0\n",
    "            translations[tr] += 1\n",
    "    return dist, translations, multiples, stops, mislengths, wildtype#, synonymous\n",
    "\n",
    "AA_CODE = \"ACDEFGHIKLMNPQRSTVWY*\"\n",
    "def check_mutants(translations, gt):\n",
    "    length = len(gt)\n",
    "    result = np.zeros((length, 21))\n",
    "    for tr in translations:\n",
    "        if tr == gt:\n",
    "            for idx, c in enumerate(tr):\n",
    "                result[idx, AA_CODE.index(c)] = 1\n",
    "        for idx, c in enumerate(tr):\n",
    "            if c != gt[idx]:\n",
    "                result[idx, AA_CODE.index(c)] += translations[tr]\n",
    "                break\n",
    "    return result\n",
    "\n",
    "def process_directory(base, catch, gt, min_overlap=50, max_overlap=250):\n",
    "    peptide_length = len(gt)\n",
    "    length = len(gt) * 3\n",
    "\n",
    "    fraction_paths_r1 = sorted([\n",
    "        f\"{base}/{path}\"\n",
    "        for path in os.listdir(base)\n",
    "        if \"R1\" in path or \"1_sequence\" in path\n",
    "    ])\n",
    "    fraction_paths_r2 = sorted([\n",
    "        f\"{base}/{path}\"\n",
    "        for path in os.listdir(base)\n",
    "        if \"R2\" in path or \"2_sequence\" in path\n",
    "    ])\n",
    "\n",
    "    sequences = []\n",
    "    results = []\n",
    "    for f1, f2 in zip(fraction_paths_r1, fraction_paths_r2):\n",
    "        seq = read_sequences(f1, f2, min_overlap=min_overlap, max_overlap=max_overlap)\n",
    "        res = gather_variants(seq, catch, gt)\n",
    "        wt = res[-1]\n",
    "        res = (check_mutants(res[1], gt), wt)\n",
    "        sequences.append(seq)\n",
    "        results.append(res)\n",
    "        \n",
    "    return sequences, results\n",
    "\n",
    "def normalise_single_run(result):\n",
    "    wt = result[-1] + 1\n",
    "    variants = result[0] + 1\n",
    "    total = wt + variants.sum()\n",
    "    wt_norm = wt / total\n",
    "    variants_norm = variants / total\n",
    "    return variants_norm, wt_norm\n",
    "\n",
    "def relative_results(normalised):\n",
    "    variant_stack = np.stack(map(lambda x: x[0], normalised))\n",
    "    wt_stack = np.array([item[-1] for item in normalised])\n",
    "    variant_stack = variant_stack / variant_stack.sum(axis=0, keepdims=True)\n",
    "    wt_stack = wt_stack / wt_stack.sum(axis=0, keepdims=True)\n",
    "    return variant_stack, wt_stack\n",
    "\n",
    "def normalise_results(results):\n",
    "    normalised = []\n",
    "    for item in results:\n",
    "        normalised.append(normalise_single_run(item))\n",
    "    relative = relative_results(normalised)\n",
    "    return normalised, relative\n",
    "\n",
    "def plot_contacts(upper, lower, positions, cutoff=None):\n",
    "    upper_ratio = sum(upper) / (sum(lower) + sum(upper))\n",
    "    gt_indices = [AA_CODE.index(gt[pos]) for pos in positions]\n",
    "    gt_matrix = np.zeros((20, len(positions)))\n",
    "    for idx, pos in enumerate(gt_indices):\n",
    "        gt_matrix[pos, idx] = 1\n",
    "\n",
    "    top = upper_ratio[positions].T / (1 - gt_matrix)\n",
    "    if cutoff:\n",
    "        top = 1.0 * (top > cutoff)\n",
    "    cmable = plt.matshow(top)\n",
    "    ax = plt.gca()\n",
    "    ax.set_yticks(range(20))\n",
    "    ax.set_yticklabels(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "    ax.set_xticks(range(len(positions)))\n",
    "    ax.set_xticklabels([pos + 1 for pos in positions])\n",
    "    plt.colorbar(cmable);\n",
    "\n",
    "def selected_fraction(variants, wt, select=None):\n",
    "    select = select if isinstance(select, (list, tuple)) else [select]\n",
    "    wt_upper = sum(wt[idx] for idx in select)\n",
    "    wt_lower = sum(wt[idx] for idx in range(len(variants)) if idx not in select)\n",
    "    upper = sum(variants[idx] for idx in select)\n",
    "    lower = sum(variants[idx] for idx in range(len(variants)) if idx not in select)\n",
    "    return lower, upper, wt_lower, wt_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write library count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch = \"aggaattcgcca\".upper()\n",
    "base = f\"{base_dir}/library_a4/\"\n",
    "_, replicates_a4 = process_directory(base, catch, gt_a4)\n",
    "\n",
    "base = f\"{base_dir}/library_a5/\"\n",
    "_, replicates_a5 = process_directory(base, catch, gt_a5, min_overlap=10)\n",
    "\n",
    "def write_count_files(path, results, gt):\n",
    "    with open(path, \"wt\") as f:\n",
    "        f.write(\"variant,num_reads_replicate_1,num_reads_replicate_2\\n\")\n",
    "        variant = \"wt\"\n",
    "        counts = [str(int(results[0][-1])) for i in range(2)]\n",
    "        f.write(f\"{variant},{','.join(counts)}\\n\")\n",
    "        for pos in range(len(gt)):\n",
    "            for aa in range(21):\n",
    "                if AA_CODE[aa] == gt[pos]:\n",
    "                    continue\n",
    "                variant = f\"{gt[pos]}{pos + 1}{AA_CODE[aa]}\"\n",
    "                counts = [str(int(results[i][0][pos, aa])) for i in range(2)]\n",
    "                f.write(f\"{variant},{','.join(counts)}\\n\")\n",
    "write_count_files(f\"{base_dir}/count_matrix_library_replicates_a4.csv\", replicates_a4, gt_a4)\n",
    "write_count_files(f\"{base_dir}/count_matrix_library_replicates_a5.csv\", replicates_a5, gt_a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read A4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch = \"aggaattcgcca\".upper()\n",
    "base = f\"{base_dir}/fractions_a4/\"\n",
    "\n",
    "relative_a4_ds3 = []\n",
    "results_a4_ds3 = []\n",
    "if not os.path.isfile(f\"{base_dir}/savefile_a4_ds3.npy\"):\n",
    "    for replicate in os.listdir(base):\n",
    "        full_path = f\"{base}/{replicate}\"\n",
    "        sequences, results = process_directory(full_path, catch, gt_a4)\n",
    "        normalised, relative = normalise_results(results)\n",
    "        variants_flat = relative[0].reshape(len(results), -1)\n",
    "        relative_a4_ds3.append(relative)\n",
    "        results_a4_ds3.append(results)\n",
    "\n",
    "    np.save(f\"{base_dir}/savefile_a4_ds3.npy\", (relative_a4_ds3, results_a4_ds3))\n",
    "else:\n",
    "    relative_a4_ds3, results_a4_ds3 = np.load(f\"{base_dir}/savefile_a4_ds3.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read A5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch = \"aggaattcgcca\".upper()\n",
    "base = f\"{base_dir}/fractions_a5/\"\n",
    "\n",
    "relative_a5_ds3 = []\n",
    "results_a5_ds3 = []\n",
    "if not os.path.isfile(f\"{base_dir}/savefile_a5_ds3.npy\"):\n",
    "    for replicate in os.listdir(base):\n",
    "        full_path = f\"{base}/{replicate}/\"\n",
    "        sequences, results = process_directory(full_path, catch, gt_a5, min_overlap=10)\n",
    "        normalised, relative = normalise_results(results)\n",
    "        variants_flat = relative[0].reshape(len(results), -1)\n",
    "        relative_a5_ds3.append(relative)\n",
    "        results_a5_ds3.append(results)\n",
    "\n",
    "    np.save(f\"{base_dir}/savefile_a5_ds3.npy\", (relative_a5_ds3, results_a5_ds3))\n",
    "else:\n",
    "    relative_a5_ds3, results_a5_ds3 = np.load(f\"{base_dir}/savefile_a5_ds3.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write fraction count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_count_files(path, results, gt):\n",
    "    for idx, replicate in enumerate(results):\n",
    "        with open(path + f\"_rep_{idx + 1}.csv\", \"wt\") as f:\n",
    "            f.write(\"variant,reads_in_fraction_1,reads_in_fraction_2,reads_in_fraction_3,reads_in_fraction_4\\n\")\n",
    "            variant = \"wt\"\n",
    "            counts = [str(int(replicate[0][-1])) for i in range(4)]\n",
    "            f.write(f\"{variant},{','.join(counts)}\\n\")\n",
    "            for pos in range(len(gt)):\n",
    "                for aa in range(21):\n",
    "                    if AA_CODE[aa] == gt[pos]:\n",
    "                        continue\n",
    "                    variant = f\"{gt[pos]}{pos + 1}{AA_CODE[aa]}\"\n",
    "                    counts = [str(int(replicate[i][0][pos, aa])) for i in range(4)]\n",
    "                    f.write(f\"{variant},{','.join(counts)}\\n\")\n",
    "        \n",
    "write_count_files(f\"{base_dir}/count_matrix_a4\", results_a4_ds3, gt_a4)\n",
    "write_count_files(f\"{base_dir}/count_matrix_a5\", results_a5_ds3, gt_a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot coverage and mean fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4 mode fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "argmax_frac = np.argmax(sum(rep[0] for rep in relative_a4_ds3) / 3, axis=0)\n",
    "argmax_wt = np.argmax(sum(rep[1] for rep in relative_a4_ds3), axis=0)\n",
    "index_a4 = np.array(list(map(AA_CODE.index, gt_a4)))\n",
    "argmax_frac[np.arange(len(index_a4)), index_a4] = argmax_wt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "cx = ax.matshow(argmax_frac.T, cmap=\"Greys_r\")\n",
    "ax.set_xticks([i * 10 - 1 if i != 0 else 0 for i in range(9)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(9)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "cax = plt.colorbar(cx)\n",
    "cax.set_ticks((0, 1, 2, 3))\n",
    "cax.set_ticklabels((0, 1, 2, 3))\n",
    "a4_dmsplot_dir = f\"{base_dir}/outputs/A4_dms_plots/\"\n",
    "os.makedirs(a4_dmsplot_dir, exist_ok=True)\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/mode_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4 mean fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean fraction for non-wt variants\n",
    "mean_frac = sum((rep[0] * np.arange(4)[:, None, None]).sum(axis=0) for rep in relative_a4_ds3) / 3\n",
    "# compute mean fraction for wt\n",
    "mean_wt = sum((rep[1] * np.arange(4)).sum(axis=0) for rep in relative_a4_ds3) / 3\n",
    "index_a4 = np.array(list(map(AA_CODE.index, gt_a4)))\n",
    "# include wt mean fraction at all wt positions\n",
    "mean_frac[np.arange(len(index_a4)), index_a4] = mean_wt\n",
    "# compute symmetric range centered around wt mean fraction\n",
    "mean_range = abs(mean_frac - mean_wt).max()\n",
    "# same for std\n",
    "std_frac = np.sqrt(sum(((rep[0] * np.arange(4)[:, None, None]).sum(axis=0) - mean_frac) ** 2 for rep in relative_a4_ds3) / 2)\n",
    "std_wt = np.sqrt(sum(((rep[1] * np.arange(4)).sum(axis=0) - mean_wt) ** 2 for rep in relative_a4_ds3) / 2)\n",
    "index_a4 = np.array(list(map(AA_CODE.index, gt_a4)))\n",
    "std_frac[np.arange(len(index_a4)), index_a4] = std_wt\n",
    "# plot mean fraction\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "cx = ax.matshow(mean_frac.T, cmap=\"RdBu_r\", vmin=mean_wt - mean_range, vmax=mean_wt + mean_range)\n",
    "ax.set_xticks([i * 10 - 1 if i != 0 else 0 for i in range(9)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(9)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "cax = plt.colorbar(cx)\n",
    "ax.set_title(\"mean fraction\")\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/mean_fraction.svg\")\n",
    "# plot standard devation of mean fraction across 3 replicates\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "cx = ax.matshow(std_frac.T, cmap=\"Greys_r\")\n",
    "ax.set_xticks([i * 10 - 1 if i != 0 else 0 for i in range(9)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(9)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "cax = plt.colorbar(cx)\n",
    "ax.set_title(\"std dev fraction\")\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/std_dev_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log number of reads per variant A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log10(sum(res[0] for rep in results_a4_ds3 for res in rep).T)\n",
    "wt_target = np.log10(sum(res[1] for rep in results_a4_ds3 for res in rep))\n",
    "target = np.where(np.array(list(gt_a4))[None, :] == np.array(list(AA_CODE))[:, None], wt_target, target)\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "cx = ax.matshow(target, cmap=\"magma\")\n",
    "ax.set_xticks([i * 10 - 1 if i != 0 else 0 for i in range(9)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(9)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "plt.colorbar(cx)\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/log_reads_per_variant.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log number of reads per fraction per variant A4 heatmap-of-heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sum(np.stack([res[0] for res in rep], axis=-1) for rep in results_a4_ds3)\n",
    "target = np.swapaxes(target, 0, 1)\n",
    "wt_target = sum(np.stack([res[1] for res in rep], axis=-1) for rep in results_a4_ds3)\n",
    "target = np.where((np.array(list(gt_a4))[None, :] == np.array(list(AA_CODE))[:, None])[..., None], wt_target, target)\n",
    "target = target.reshape(*target.shape[:2], 2, 2)\n",
    "target /= target.sum(axis=(-1, -2), keepdims=True)\n",
    "target = np.moveaxis(target, -2, 1)\n",
    "target = np.moveaxis(target, -1, 3)\n",
    "target = target.reshape(21 * 2, 87 * 2)\n",
    "print(target.shape)\n",
    "fig, ax = plt.subplots(figsize=(20, 4), dpi=600)\n",
    "cx = ax.matshow(target, cmap=\"magma\")\n",
    "ax.set_xticks([(i * 10 - 1) * 2 + 0.5 if i != 0 else 0.5 for i in range(9)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(9)])\n",
    "ax.set_yticks([2 * i + 0.5 for i in range(21)])\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "ax.hlines(2 * np.arange(21) - 0.5, -0.5, 87 * 2 - 0.5, color=\"w\")\n",
    "ax.vlines(2 * np.arange(87) - 0.5, -0.5, 21 * 2 - 0.5, color=\"w\")\n",
    "#ax.set_xlim((0 - 0.5, 87 * 2 -0.5))\n",
    "#ax.grid(c='k', ls='-', lw='2')\n",
    "ax.set_title(\"AcrIIA4 reads-per-fraction heatmap\", fontsize=14)\n",
    "ax.set_xlabel(\"sequence position\", fontsize=12)\n",
    "ax.set_ylabel(\"variant\", fontsize=12)\n",
    "\n",
    "plt.colorbar(cx)\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/log_reads_per_variant_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4 overview fraction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "mean_dist_a4 = sum(rep[0] for rep in relative_a4_ds3) / 3\n",
    "mean_dist_a4_wt = sum(rep[1] for rep in relative_a4_ds3) / 3\n",
    "mean_dist_a4[:, np.arange(len(index_a4)), index_a4] = mean_dist_a4_wt[:, None]\n",
    "std_dist_a4 = np.sqrt(sum((rep[0] - mean_dist_a4) ** 2 for rep in relative_a4_ds3) / 2)\n",
    "std_dist_a4_wt = np.sqrt(sum((rep[1] - mean_dist_a4_wt) ** 2 for rep in relative_a4_ds3) / 2)\n",
    "std_dist_a4[:, np.arange(len(index_a4)), index_a4] = std_dist_a4_wt[:, None]\n",
    "fig = None\n",
    "ax = None\n",
    "with PdfPages(f\"outputs/overview_figures/overview_fractions_a4_pages.pdf\") as pdf:\n",
    "    for pos in range(87):\n",
    "        if pos % 10 == 0:\n",
    "            if fig is not None:\n",
    "                pdf.savefig(fig)\n",
    "            remaining = len(gt_a4) - pos\n",
    "            size = min(10, remaining)\n",
    "            fig, ax = plt.subplots(size, 21, figsize=(21 * 4, size * 4))\n",
    "        ax[pos % 10, 0].set_ylabel(\"fraction of reads\")\n",
    "        for aa in range(21):\n",
    "            title = f\"{gt_a4[pos]}{pos + 1}{AA_CODE[aa]}\"\n",
    "            if gt_a4[pos] == AA_CODE[aa]:\n",
    "                title = \"wt\"\n",
    "            ax[pos % 10, aa].set_title(title)\n",
    "            ax[pos % 10, aa].bar(np.arange(4), mean_dist_a4[:, pos, aa], width=0.5, yerr=std_dist_a4[:, pos, aa])\n",
    "            ax[pos % 10, aa].set_ylim(0.0, 1.0)\n",
    "            ax[pos % 10, aa].set_xticks((0, 1, 2, 3))\n",
    "            ax[pos % 10, aa].set_xticklabels((1, 2, 3, 4))\n",
    "            ax[-1, aa].set_xlabel(\"sorted fraction ID\")\n",
    "    pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5 mode fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "argmax_a5 = np.argmax(sum(rep[0] for rep in relative_a5_ds3) / 3, axis=0)\n",
    "argmax_a5_wt = np.argmax(sum(rep[1] for rep in relative_a5_ds3) / 3, axis=0)\n",
    "index_a5 = np.array(list(map(AA_CODE.index, gt_a5)))\n",
    "argmax_a5[np.arange(len(index_a5)), index_a5] = argmax_a5_wt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(len(gt_a5) / 4, 20 / 4))\n",
    "cx = ax.matshow(argmax_a5.T, cmap=\"Greys_r\")\n",
    "ax.set_yticks(np.arange(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "ax.set_xticks([10 * i - 1 if i != 0 else 0 for i in range(15)])\n",
    "ax.set_xticklabels([10 * i if i != 0 else 1 for i in range(15)])\n",
    "cax = plt.colorbar(cx)\n",
    "cax.set_ticks((0, 1, 2, 3))\n",
    "cax.set_ticklabels((0, 1, 2, 3))\n",
    "a5_dmsplot_dir = f\"{base_dir}/outputs/A5_dms_plots/\"\n",
    "os.makedirs(a5_dmsplot_dir, exist_ok=True)\n",
    "plt.savefig(f\"{a5_dmsplot_dir}/mode_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5 mean fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean fraction for non-wt variants\n",
    "mean_frac_a5 = sum((rep[0] * np.arange(4)[:, None, None]).sum(axis=0) for rep in relative_a5_ds3) / 3\n",
    "# compute mean fraction for wt\n",
    "mean_wt_a5 = sum((rep[1] * np.arange(4)).sum(axis=0) for rep in relative_a5_ds3) / 3\n",
    "# include wt mean fraction at all wt positions\n",
    "mean_frac_a5[np.arange(len(index_a5)), index_a5] = mean_wt_a5\n",
    "# compute symmetric range centered around wt mean fraction\n",
    "mean_range_a5 = abs(mean_frac_a5 - mean_wt_a5).max()\n",
    "# same for std\n",
    "std_frac_a5 = np.sqrt(sum(((rep[0] * np.arange(4)[:, None, None]).sum(axis=0) - mean_frac_a5) ** 2 for rep in relative_a5_ds3) / 2)\n",
    "std_wt_a5 = np.sqrt(sum(((rep[1] * np.arange(4)).sum(axis=0) - mean_wt_a5) ** 2 for rep in relative_a5_ds3) / 2)\n",
    "std_frac_a5[np.arange(len(index_a5)), index_a5] = std_wt_a5\n",
    "# plot mean fraction\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30, 4))\n",
    "cx = ax.matshow(mean_frac_a5.T, cmap=\"RdBu_r\", vmin=mean_wt_a5 - mean_range_a5, vmax=mean_wt_a5 + mean_range_a5)\n",
    "ax.set_xticks([10 * i - 1 if i != 0 else 0 for i in range(15)])\n",
    "ax.set_xticklabels([10 * i if i != 0 else 1 for i in range(15)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "cax = plt.colorbar(cx)\n",
    "ax.set_title(\"mean fraction\")\n",
    "plt.savefig(f\"{a5_dmsplot_dir}/mean_fraction.svg\")\n",
    "# plot standard devation of mean fraction across 3 replicates\n",
    "fig, ax = plt.subplots(1, 1, figsize=(30, 4))\n",
    "cx = ax.matshow(std_frac_a5.T, cmap=\"Greys_r\")\n",
    "ax.set_xticks([10 * i - 1 if i != 0 else 0 for i in range(15)])\n",
    "ax.set_xticklabels([10 * i if i != 0 else 1 for i in range(15)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "cax = plt.colorbar(cx)\n",
    "ax.set_title(\"std dev fraction\")\n",
    "plt.savefig(f\"{a5_dmsplot_dir}/std_dev_fraction.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5 log readcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log10(sum(res[0] for rep in results_a5_ds3 for res in rep).T)\n",
    "wt_target = np.log10(sum(res[1] for rep in results_a5_ds3 for res in rep))\n",
    "target = np.where(np.array(list(gt_a5))[None, :] == np.array(list(AA_CODE))[:, None], wt_target, target)\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "cx = ax.matshow(target, cmap=\"magma\")\n",
    "ax.set_xticks([10 * i - 1 if i != 0 else 0 for i in range(15)])\n",
    "ax.set_xticklabels([10 * i if i != 0 else 1 for i in range(15)])\n",
    "ax.set_yticks(range(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "plt.colorbar(cx)\n",
    "plt.savefig(f\"{a5_dmsplot_dir}/log_reads_per_variant.svg\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log reads per fraction A5 heatmap-of-heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sum(np.stack([res[0] for res in rep], axis=-1) for rep in results_a5_ds3)\n",
    "target = np.swapaxes(target, 0, 1)\n",
    "wt_target = sum(np.stack([res[1] for res in rep], axis=-1) for rep in results_a5_ds3)\n",
    "target = np.where((np.array(list(gt_a5))[None, :] == np.array(list(AA_CODE))[:, None])[..., None], wt_target, target)\n",
    "target = target.reshape(*target.shape[:2], 2, 2)\n",
    "target /= target.sum(axis=(-1, -2), keepdims=True)\n",
    "target = np.moveaxis(target, -2, 1)\n",
    "target = np.moveaxis(target, -1, 3)\n",
    "target = target.reshape(21 * 2, (len(gt_a5)) * 2)\n",
    "print(target.shape)\n",
    "fig, ax = plt.subplots(figsize=(32, 4), dpi=600)\n",
    "cx = ax.matshow(target, cmap=\"magma\")\n",
    "ax.set_xticks([(i * 10 - 1) * 2 + 0.5 if i != 0 else 0.5 for i in range(15)])\n",
    "ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(15)])\n",
    "ax.set_yticks([2 * i + 0.5 for i in range(21)])\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "ax.hlines(2 * np.arange(21) - 0.5, -0.5, len(gt_a5) * 2 - 0.5, color=\"w\")\n",
    "ax.vlines(2 * np.arange(len(gt_a5)) - 0.5, -0.5, 21 * 2 - 0.5, color=\"w\")\n",
    "#ax.set_xlim((0 - 0.5, 87 * 2 -0.5))\n",
    "#ax.grid(c='k', ls='-', lw='2')\n",
    "ax.set_title(\"AcrIIA5 reads-per-fraction heatmap\", fontsize=14)\n",
    "ax.set_xlabel(\"sequence position\", fontsize=12)\n",
    "ax.set_ylabel(\"variant\", fontsize=12)\n",
    "plt.colorbar(cx)\n",
    "plt.savefig(f\"{a4_dmsplot_dir}/log_reads_per_variant_fraction_a5.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5 overview fraction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "mean_dist_a5 = sum(rep[0] for rep in relative_a5_ds3) / 3\n",
    "mean_dist_a5_wt = sum(rep[1] for rep in relative_a5_ds3) / 3\n",
    "mean_dist_a5[:, np.arange(len(index_a5)), index_a5] = mean_dist_a5_wt[:, None]\n",
    "std_dist_a5 = np.sqrt(sum((rep[0] - mean_dist_a5) ** 2 for rep in relative_a5_ds3) / 2)\n",
    "std_dist_a5_wt = np.sqrt(sum((rep[1] - mean_dist_a5_wt) ** 2 for rep in relative_a5_ds3) / 2)\n",
    "std_dist_a5[:, np.arange(len(index_a5)), index_a5] = std_dist_a5_wt[:, None]\n",
    "fig = None\n",
    "ax = None\n",
    "with PdfPages(f\"outputs/overview_figures/overview_fractions_a5_pages.pdf\") as pdf:\n",
    "    for pos in range(len(gt_a5)):\n",
    "        if pos % 10 == 0:\n",
    "            if fig is not None:\n",
    "                pdf.savefig(fig)\n",
    "            remaining = len(gt_a5) - pos\n",
    "            size = min(10, remaining)\n",
    "            fig, ax = plt.subplots(size, 21, figsize=(21 * 4, size * 4))\n",
    "        ax[pos % 10, 0].set_ylabel(\"fraction of reads\")\n",
    "        for aa in range(21):\n",
    "            title = f\"{gt_a5[pos]}{pos + 1}{AA_CODE[aa]}\"\n",
    "            if gt_a5[pos] == AA_CODE[aa]:\n",
    "                title = \"wt\"\n",
    "            ax[pos % 10, aa].set_title(title)\n",
    "            ax[pos % 10, aa].bar(np.arange(4), mean_dist_a5[:, pos, aa], width=0.5, yerr=std_dist_a5[:, pos, aa])\n",
    "            ax[pos % 10, aa].set_ylim(0.0, 1.0)\n",
    "            ax[pos % 10, aa].set_xticks((0, 1, 2, 3))\n",
    "            ax[pos % 10, aa].set_xticklabels((1, 2, 3, 4))\n",
    "            ax[-1, aa].set_xlabel(\"sorted fraction ID\")\n",
    "    pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit FACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FlowCal\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.distributions import MixtureSameFamily, Normal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(path, relative, start, end, count, replicates=(0,)):\n",
    "    targets = []\n",
    "    vals = []\n",
    "    names = []\n",
    "    for p in sorted(os.listdir(path)):\n",
    "        kind = p.split(\".\")[0].split(\"_\")[1]\n",
    "        original = kind[0]\n",
    "        changed = kind[-1]\n",
    "        position = int(kind[1:-1])\n",
    "        data = FlowCal.io.FCSData(f\"{path}/{p}\")\n",
    "        target = np.log(data[:, -1][data[:, -1] >= 1])\n",
    "        bins = start + np.arange(0, count) * (end - start) / count + (end - start) / count / 2\n",
    "        unique, counts = np.unique(np.argmin(abs(target[:, None] - bins[None, :]), axis=-1), return_counts=True)\n",
    "        target = torch.zeros(count)\n",
    "        target[unique] = torch.tensor(counts).float()\n",
    "        target = target / target.sum()\n",
    "        targets += len(replicates) * [target[None]]\n",
    "        names += len(replicates) * [kind]\n",
    "        changed = AA_CODE.index(changed)\n",
    "        vals += [torch.tensor(relative[rep][0][:, position - 1, changed])[None] for rep in replicates]\n",
    "    vals = torch.cat(vals, dim=0).float()#.view(-1, 6, *vals[0].shape[1:])\n",
    "    targets = torch.cat(targets, dim=0).float()#.view(-1, 6, *targets[0].shape[1:])\n",
    "    return vals, targets, names\n",
    "    \n",
    "def fit_facs(relative, path, frac=4, start=4, end=12, count=20, steps=100000, mode=\"linear\", drop=None):\n",
    "    linear = torch.nn.Linear(frac, count, bias=False)\n",
    "    with torch.no_grad():\n",
    "        linear.weight.zero_()\n",
    "    loss = torch.nn.KLDivLoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.AdamW(linear.parameters(), lr=1e-4)\n",
    "    vals, targets, _ = make_dataset(path, relative, start, end, count, replicates=(0, 1, 2))\n",
    "    print(vals.shape, targets.shape)\n",
    "    indices = torch.arange(0, targets.size(0), dtype=torch.long)\n",
    "    if drop is not None:\n",
    "        indices = torch.tensor([i for i in indices if i != drop])\n",
    "    targets = targets[indices]\n",
    "    vals = vals[indices]\n",
    "    for idx in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        batch = torch.arange(targets.shape[0]) // 6 % 4 != 0\n",
    "        v = vals.reshape(-1, vals.shape[-1])\n",
    "        t = targets.reshape(-1, targets.shape[-1])\n",
    "        out = linear(v[batch])\n",
    "        out = out.log_softmax(dim=1)\n",
    "        cross_entropy = -((out * t[batch])).sum(axis=-1).mean()\n",
    "        mean_error = (abs(((out.exp() - t[batch]) * torch.arange(count)).sum(axis=-1))).mean()\n",
    "        val = cross_entropy\n",
    "        if idx % 500 == 0:\n",
    "            print(float(cross_entropy), float(mean_error), end=\"\\r\", flush=True)\n",
    "        val.backward()\n",
    "        optimizer.step()\n",
    "    return linear\n",
    "\n",
    "def eval_facs(linears, relative, path, frac=4, start=4, end=12, count=20, steps=100000):\n",
    "    vals, targets, _ = make_dataset(path, relative, start, end, count, replicates=(0,))\n",
    "\n",
    "    errors = []\n",
    "    predictions = []\n",
    "    for idx, reg in enumerate(linears):\n",
    "        errors.append((abs(reg(vals)[idx].softmax(dim=0) - targets[idx])).mean())\n",
    "        predictions.append(reg(vals)[idx].softmax(dim=0).detach())\n",
    "    return errors, predictions, targets\n",
    "        \n",
    "def predict_facs(linear, data, frac=8):\n",
    "    results = []\n",
    "    for rep in data:\n",
    "        inputs = torch.tensor(rep[0]).float().permute(1, 2, 0)\n",
    "        v = inputs.view(-1, frac)\n",
    "        features = v#torch.cat((v, (v[:, :, None] * v[:, None, :]).reshape(v.shape[0], -1)), dim=-1)\n",
    "        pred = linear(features)\n",
    "        pred = pred.view(*inputs.shape[:2], pred.size(1))\n",
    "        results.append(pred.softmax(dim=-1)[None])\n",
    "    return torch.cat(results, axis=0)\n",
    "\n",
    "def predict_wt(linear, data, frac=8):\n",
    "    results = []\n",
    "    for rep in data:\n",
    "        inputs = torch.tensor(rep[1]).float()[None]\n",
    "        pred = linear(inputs.view(-1, frac)).softmax(dim=-1)\n",
    "        results.append(pred)\n",
    "    return torch.cat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_a4_ds3 = fit_facs(relative_a4_ds3, f\"{base_dir}/facs/A4/\", mode=\"linear\", start=0, end=14, count=20, drop=None)\n",
    "linear_a5_ds3 = fit_facs(relative_a5_ds3, f\"{base_dir}/facs/A5/\", mode=\"linear\", start=0, end=14, count=20, drop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = plt.matshow(linear_a4_ds3.weight.detach().softmax(axis=0).numpy().T)\n",
    "plt.colorbar(cx)\n",
    "linear_dir = f\"{base_dir}/outputs/linear_model/\"\n",
    "os.makedirs(linear_dir, exist_ok=True)\n",
    "plt.savefig(f\"{linear_dir}/a4_weight.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linears_a4_ds3 = []\n",
    "for idx in range(16):\n",
    "    linears_a4_ds3.append(fit_facs(relative_a4_ds3, f\"{base_dir}/facs/A4/\", mode=\"linear\", start=0, end=14, count=20, drop=idx))\n",
    "linears_a5_ds3 = []\n",
    "for idx in range(16):\n",
    "    linears_a5_ds3.append(fit_facs(relative_a5_ds3, f\"{base_dir}/facs/A5/\", mode=\"linear\", start=0, end=14, count=20, drop=idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if not os.path.isfile(f\"{base_dir}/backup.torch\"):\n",
    "    torch.save(dict(\n",
    "        linear_a4_ds3=linear_a4_ds3,\n",
    "        linear_a5_ds3=linear_a5_ds3,\n",
    "        linears_a4_ds3=linears_a4_ds3,\n",
    "        linears_a5_ds3=linears_a5_ds3\n",
    "    ), f\"{base_dir}/backup.torch\")\n",
    "else:\n",
    "    backup = torch.load(f\"{base_dir}/backup.torch\")\n",
    "    linear_a4_ds3 = backup[\"linear_a4_ds3\"]\n",
    "    linear_a5_ds3 = backup[\"linear_a5_ds3\"]\n",
    "    linears_a4_ds3 = backup[\"linears_a4_ds3\"]\n",
    "    linears_a5_ds3 = backup[\"linears_a5_ds3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_a4, cpredictions_a4, ctargets_a4 = eval_facs(linears_a4_ds3, relative_a4_ds3, f\"{base_dir}/facs/A4/\", count=20, frac=4, start=0, end=14)\n",
    "errors_a5, cpredictions_a5, ctargets_a5 = eval_facs(linears_a5_ds3, relative_a5_ds3, f\"{base_dir}/facs/A5/\", count=20, frac=4, start=0, end=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot cross-validation error for variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_names_a4 = []\n",
    "for p in os.listdir(f\"{base_dir}/facs/A4/\"):\n",
    "        kind = p.split(\".\")[0].split(\"_\")[1]\n",
    "        rep = p.split(\".\")[0].split(\"_\")[2]\n",
    "        if rep != \"1\":\n",
    "            continue\n",
    "        original = kind[0]\n",
    "        changed = kind[-1]\n",
    "        variant_names_a4.append(kind)\n",
    "variant_names_a5 = []\n",
    "for p in os.listdir(f\"{base_dir}/facs/A5/\"):\n",
    "        kind = p.split(\".\")[0].split(\"_\")[1]\n",
    "        rep = p.split(\".\")[0].split(\"_\")[2]\n",
    "        if rep != \"1\":\n",
    "            continue\n",
    "        original = kind[0]\n",
    "        changed = kind[-1]\n",
    "        variant_names_a5.append(kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_names = dict(\n",
    "    a4=variant_names_a4, a5=variant_names_a5#, a4_f2=variant_names_a4\n",
    ")\n",
    "print(variant_names)\n",
    "ctargets = dict(\n",
    "    a4=ctargets_a4, a5=ctargets_a5#, a4_f2=ctargets_a4_f2\n",
    ")\n",
    "cpredictions = dict(\n",
    "    a4=cpredictions_a4, a5=cpredictions_a5#, a4_f2=cpredictions_a4_f2\n",
    ")\n",
    "errors = dict(\n",
    "    a4=errors_a4, a5=errors_a5#, a4_f2=errors_a4_f2\n",
    ")\n",
    "bins = 0.0 + np.arange(0, 20) * 14.0 / 20 + 14.0 / 20 / 2\n",
    "for acrkind in (\"a4\", \"a5\"):#, \"a4_f2\"):\n",
    "    for idx, name in enumerate(variant_names[acrkind][:16]):\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.set_title(name)\n",
    "        ax.fill_between(bins, ctargets[acrkind][idx], alpha=0.5)\n",
    "        ax.fill_between(bins, cpredictions[acrkind][idx], alpha=0.5)\n",
    "        ax.set_ylim(0.0, 0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{base_dir}/error_{acrkind}_{name}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot mean cross-validation error across all variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acrkind in (\"a4\", \"a5\"):#, \"a4_f2\"):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.bar(list(range(len(errors[acrkind]))), [e.detach() for e in errors[acrkind]])\n",
    "    ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    ax.set_xticks(range(16))\n",
    "    print(variant_names[acrkind])\n",
    "    ax.set_xticklabels(variant_names[acrkind][:16])\n",
    "    ax.set_ylim(0.0, 0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}/leave_one_out_{acrkind}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict FACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict A4 & A5 FACS profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_rel_a4 = predict_facs(linear_a4_ds3.eval(), relative_a4_ds3, frac=4).detach().numpy()\n",
    "pf_wt_a4 = predict_wt(linear_a4_ds3.eval(), relative_a4_ds3, frac=4).detach().numpy()\n",
    "pf_rel_a5 = predict_facs(linear_a5_ds3.eval(), relative_a5_ds3, frac=4).detach().numpy()\n",
    "pf_wt_a5 = predict_wt(linear_a5_ds3.eval(), relative_a5_ds3, frac=4).detach().numpy()\n",
    "\n",
    "conversion_factor = (np.arange(pf_rel_a4.shape[-1]) / pf_rel_a4.shape[-1] + 1 / pf_rel_a4.shape[-1] / 2) * 14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overview(path, rel, wt, index, gt):\n",
    "    mean = rel.mean(axis=0)\n",
    "    mean_wt = wt.mean(axis=0)\n",
    "    mean[np.arange(len(index)), index, :] = mean_wt[None, :]\n",
    "    std = rel.std(axis=0)\n",
    "    std_wt = wt.std(axis=0)\n",
    "    std[np.arange(len(index)), index, :] = std_wt[None, :]\n",
    "    #fig, ax = plt.subplots(rel.shape[1], 21, figsize=(21 * 4, len(gt) * 4))\n",
    "    fig = None\n",
    "    ax = None\n",
    "    with PdfPages(path) as pdf:\n",
    "        for pos in range(rel.shape[1]):\n",
    "            if pos % 10 == 0:\n",
    "                if fig is not None:\n",
    "                    pdf.savefig(fig)\n",
    "                remaining = rel.shape[1] - pos\n",
    "                size = min(10, remaining)\n",
    "                fig, ax = plt.subplots(size, 21, figsize=(21 * 4, size * 4))\n",
    "            ax[pos % 10, 0].set_ylabel(\"predicted probability\")\n",
    "            for aa in range(21):\n",
    "                title = f\"{gt[pos]}{pos + 1}{AA_CODE[aa]}\"\n",
    "                if gt[pos % 10] == AA_CODE[aa]:\n",
    "                    title = \"wt\"\n",
    "                ax[pos % 10, aa].set_title(title)\n",
    "                ax[pos % 10, aa].bar(np.arange(20), mean[pos, aa, :], width=0.5, yerr=std[pos, aa, :])\n",
    "                ax[pos % 10, aa].set_ylim(0.0, 1.0)\n",
    "                ax[pos % 10, aa].set_xticks(np.arange(0, 20, 5))\n",
    "                ax[pos % 10, aa].set_xticklabels([f\"{i:.2f}\" for i in conversion_factor[::5]])\n",
    "                ax[-1, aa].set_xlabel(\"log fluorescence intensity\")\n",
    "        pdf.savefig(fig)\n",
    "plot_overview(\"outputs/overview_figures/overview_predictions_a4_pages.pdf\", pf_rel_a4, pf_wt_a4, index_a4, gt_a4)\n",
    "plot_overview(\"outputs/overview_figures/overview_predictions_a5_pages.pdf\", pf_rel_a5, pf_wt_a5, index_a5, gt_a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"a4_mean_prediction.csv\", \"wt\") as f:\n",
    "    f.write(f\"variant_name,value,std\\nwt,{mean_pred_mean_a4[0, AA_CODE.index(gt_a4[0])]},{mean_pred_std_a4[0, AA_CODE.index(gt_a4[0])]}\\n\")\n",
    "    for pos in range(mean_pred_mean_a4.shape[0]):\n",
    "        for aa in range(21):\n",
    "            aa_name = AA_CODE[aa]\n",
    "            if aa_name == gt_a4[pos]:\n",
    "                continue\n",
    "            val = mean_pred_mean_a4[pos, aa]\n",
    "            std = mean_pred_std_a4[pos, aa]\n",
    "            f.write(f\"{gt_a4[pos]}{pos + 1}{aa_name},{val},{std}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"a5_mean_prediction.csv\", \"wt\") as f:\n",
    "    f.write(f\"variant_name,value,std\\nwt,{mean_pred_mean_a5[0, AA_CODE.index(gt_a5[0])]},{mean_pred_std_a5[0, AA_CODE.index(gt_a5[0])]}\\n\")\n",
    "    for pos in range(mean_pred_mean_a5.shape[0]):\n",
    "        for aa in range(21):\n",
    "            aa_name = AA_CODE[aa]\n",
    "            if aa_name == gt_a5[pos]:\n",
    "                continue\n",
    "            val = mean_pred_mean_a5[pos, aa]\n",
    "            std = mean_pred_std_a5[pos, aa]\n",
    "            f.write(f\"{gt_a5[pos]}{pos + 1}{aa_name},{val},{std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation tolerance A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_rel_a4_mean = (pf_rel_a4.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "pf_wt_a4_mean = (pf_wt_a4.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "wt_mask = np.zeros_like(pf_rel_a4_mean)\n",
    "for idx, aa in enumerate(gt_a4):\n",
    "    aa = AA_CODE.index(aa)\n",
    "    wt_mask[idx, aa] = 1\n",
    "wt_mask = wt_mask > 0\n",
    "pf_rel_a4_mean[wt_mask] = np.nan\n",
    "for threshold in [0.9, 0.95, 1.0]:\n",
    "    print(threshold, (pf_rel_a4_mean >= pf_wt_a4_mean * threshold).sum() / (1 - wt_mask).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_rel_a5_mean = (pf_rel_a5.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "pf_wt_a5_mean = (pf_wt_a5.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "wt_mask = np.zeros_like(pf_rel_a5_mean)\n",
    "for idx, aa in enumerate(gt_a5):\n",
    "    aa = AA_CODE.index(aa)\n",
    "    wt_mask[idx, aa] = 1\n",
    "wt_mask = wt_mask > 0\n",
    "pf_rel_a5_mean[wt_mask] = np.nan\n",
    "for threshold in [0.9, 0.95, 1.0]:\n",
    "    print(threshold, (pf_rel_a5_mean >= pf_wt_a5_mean * threshold).sum() / (1 - wt_mask).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with Kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations\n",
    "kd_variants = dict(WT=8.31, G38C=14.8, N25G=8.69, E70T=112, E70D=24.5, Y67K=332000, M77A=76)\n",
    "mean_bin_variants = dict(WT=pf_wt_a4_mean)\n",
    "for name in kd_variants:\n",
    "    if name not in mean_bin_variants:\n",
    "        pos = int(name[1:-1]) - 1\n",
    "        val = AA_CODE.index(name[-1])\n",
    "        mean_bin_variants[name] = pf_rel_a4_mean[pos, val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_names = sorted(list(kd_variants.keys()))\n",
    "kd_variants_rv = [1 / kd_variants[name] for name in sorted_names]\n",
    "mean_bin_variants_v = [mean_bin_variants[name] for name in sorted_names]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(mean_bin_variants_v, kd_variants_rv)\n",
    "for i, txt in enumerate(sorted_names):\n",
    "    ax.annotate(txt, (mean_bin_variants_v[i], kd_variants_rv[i]))\n",
    "ax.set_xlabel(\"mean log fluorescence intensity\")\n",
    "ax.set_ylabel(\"1 / Kd\")\n",
    "plt.savefig(f\"{base_dir}/outputs/Kd_correlation_a4.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waterfall plot\n",
    "COLORS=[\"teal\", \"orange\", \"purple\", \"red\", \"green\", \"grey\", \"brown\"]\n",
    "def waterfall(path, rel, wt, sequence, names, ymin=0.0, ymax=9.0):\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))\n",
    "    rel = (rel.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "    wt = (wt.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "    wt_mask = np.zeros_like(rel)\n",
    "    for idx, aa in enumerate(sequence):\n",
    "        aa = AA_CODE.index(aa)\n",
    "        wt_mask[idx, aa] = 1\n",
    "    wt_mask = wt_mask > 0\n",
    "    rel[wt_mask] = np.nan\n",
    "    rel[wt_mask.nonzero()[0][0]] = wt\n",
    "    index = np.argsort(rel.reshape(-1))\n",
    "    revindex = np.arange(index.shape[0])\n",
    "    revindex[index] = np.arange(index.shape[0])\n",
    "    plotrel = rel.reshape(-1)[index]\n",
    "    for idy, name in enumerate(names):\n",
    "        if name == \"WT\":\n",
    "            pos = 0\n",
    "            aa = AA_CODE.index(sequence[pos])\n",
    "            ii = np.ravel_multi_index([pos, aa], rel.shape)\n",
    "            val = rel.reshape(-1)[ii]\n",
    "            val2 = rel[pos, aa]\n",
    "            ax.vlines(revindex[ii], 0.0, val, label=name, color=\"black\")\n",
    "        else:\n",
    "            pos = int(name[1:-1]) - 1\n",
    "            aa = AA_CODE.index(name[-1])\n",
    "            ii = np.ravel_multi_index([pos, aa], rel.shape)\n",
    "            val = rel.reshape(-1)[ii]\n",
    "            val2 = rel[pos, aa]\n",
    "            ax.vlines(revindex[ii], 0.0, val, label=name, color=COLORS[idy])\n",
    "    ax.fill_between(np.arange(plotrel.shape[0]), plotrel, np.zeros_like(plotrel), color=\"#DD8888\")\n",
    "    ax.legend()\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "waterfall(None, pf_rel_a4, pf_wt_a4, gt_a4, kd_variants)\n",
    "plt.savefig(f\"{base_dir}/outputs/waterfall_a4.svg\", dpi=600)\n",
    "waterfall(None, pf_rel_a5, pf_wt_a5, gt_a5, [\"WT\", \"G3I\", \"R13F\", \"K58M\", \"D69A\", \"E76L\", \"G3W\"], ymin=4, ymax=7)\n",
    "plt.savefig(f\"{base_dir}/outputs/waterfall_a5.svg\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def dot_heatmap(predictions, predictions_wt, gt, path, scale=0.25):\n",
    "    pf_rel = predictions\n",
    "    pf_wt = predictions_wt\n",
    "    pf_corr = pf_rel - pf_wt[:, None, None]#pf_rel.mean(axis=(0, 1), keepdims=True)\n",
    "    pf_corr = pf_corr * conversion_factor\n",
    "    pf_mean = pf_corr.sum(axis=-1)#pf_corr.shape[-1]\n",
    "    wt = pf_wt * conversion_factor\n",
    "    wt = wt.sum(axis=-1)\n",
    "    pf_mean, pf_std = pf_mean.mean(axis=0), pf_mean.std(axis=0)\n",
    "    std_max = pf_std.max()\n",
    "    std_min = 0#pf_std.min()\n",
    "    std_norm = (pf_std - std_min) / (std_max - std_min)\n",
    "    print(std_max, std_min)\n",
    "    conf_norm = 1 - std_norm\n",
    "    wt = wt.mean(axis=0)\n",
    "    print(wt)\n",
    "    #pf_mean = pf_mean + 0.5\n",
    "    pmax = -pf_mean.min()\n",
    "    pmax = max(pmax, pf_mean.max())\n",
    "    pmin = -pmax\n",
    "    pmax = pmax + wt\n",
    "    pmin = pmin + wt\n",
    "    #pf_mean = pf_mean / pmax\n",
    "\n",
    "    x = 0.25\n",
    "    width = pf_rel.shape[1]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width * x, 20 * x), sharex=False, sharey=False)\n",
    "\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    c = []\n",
    "    s = []\n",
    "    for idy in range(20):\n",
    "        for idx in range(width):\n",
    "            data_x.append(idx)\n",
    "            data_y.append(-idy)\n",
    "            mean = pf_mean[idx, idy] + wt\n",
    "            if AA_CODE.index(gt[idx]) == idy:\n",
    "                c.append(100)\n",
    "                s.append(1)\n",
    "            else:\n",
    "                c.append(mean)\n",
    "                s.append(conf_norm[idx, idy] ** 2)\n",
    "\n",
    "    #print(min(s), max(s))\n",
    "    s = [\n",
    "        0.9 * x ** 2\n",
    "        for x in s\n",
    "    ]\n",
    "    cmap = cm.bwr\n",
    "\n",
    "    ca = plt.scatter(data_x, data_y, c=c, s=[sv * 100 for sv in s],\n",
    "                     cmap=cmap, vmin=pmin, vmax=pmax, edgecolors=\"black\", linewidth=0.6)\n",
    "    ca.cmap.set_over(\"black\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar(ca)\n",
    "    fig.savefig(path)\n",
    "\n",
    "def square_heatmap(rel, wt, gt, path, scale=4):\n",
    "    pf_rel = rel\n",
    "    pf_wt = wt\n",
    "    pf_corr = pf_rel - pf_wt[:, None, None]\n",
    "    pf_corr = pf_corr * conversion_factor\n",
    "    pf_mean = pf_corr.sum(axis=-1)\n",
    "    wt = pf_wt * conversion_factor\n",
    "    wt = wt.sum(axis=-1)\n",
    "    pf_mean, pf_std = pf_mean.mean(axis=0), pf_mean.std(axis=0)\n",
    "    std_max = pf_std.max()\n",
    "    std_min = 0\n",
    "    std_norm = (pf_std - std_min) / (std_max - std_min)\n",
    "    conf_norm = 1 - std_norm\n",
    "    wt = wt.mean(axis=0)\n",
    "    pmax = -pf_mean.min()\n",
    "    pmax = max(pmax, pf_mean.max())\n",
    "    pmin = -pmax\n",
    "    pmax = pmax + wt\n",
    "    pmin = pmin + wt\n",
    "    gt_mask = np.zeros_like(pf_mean)\n",
    "    gt_mask[np.arange(pf_mean.shape[0], dtype=np.int32), np.array([AA_CODE.index(aa) for aa in gt])] = 1\n",
    "    gt_mask = gt_mask > 0\n",
    "    pf_mean = np.where(gt_mask, 100, pf_mean + wt)\n",
    "\n",
    "    x = 0.25\n",
    "    width = pf_rel.shape[1]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width * x, 20 * x), sharex=False, sharey=False)\n",
    "    cmap = cm.bwr\n",
    "    cax = ax.matshow(pf_mean.T, cmap=cmap, vmin=pmin, vmax=pmax)\n",
    "    tick_count = len(gt) // 10 + 1\n",
    "    ax.set_xticks([i * 10 - 1 if i != 0 else 0 for i in range(tick_count)])\n",
    "    ax.set_xticklabels([i * 10 if i != 0 else 1 for i in range(tick_count)])\n",
    "    ax.set_yticks(np.arange(21))\n",
    "    ax.set_yticklabels(AA_CODE)\n",
    "    cax.cmap.set_over(\"black\")\n",
    "    plt.colorbar(cax)\n",
    "    fig.savefig(path)\n",
    "\n",
    "dot_heatmap(pf_rel_a4, pf_wt_a4, gt_a4, f\"{base_dir}/outputs/large-prediction-dotheatmap-A4-final.svg\", scale=4)\n",
    "square_heatmap(pf_rel_a4, pf_wt_a4, gt_a4, f\"{base_dir}/outputs/large-prediction-squareheatmap-A4-final.svg\", scale=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amino acid type overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position-wise violin plots\n",
    "cas_positions = [13, 16, 17, 35, 37, 38, 39, 66, 68, 69]\n",
    "non_cas_positions = [idx for idx in range(87) if idx not in cas_positions]\n",
    "surface_positions = [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81] # TODO\n",
    "core_positions = [5, 9, 16, 29, 31, 33, 50, 54, 58, 72, 76]\n",
    "polar = \"RNDCEQHKSTWY\"\n",
    "non_polar = \"AGILMFPV\"\n",
    "basic = \"RHK\"\n",
    "acidic = \"DE\"\n",
    "neutral = \"ANCQGILMFPSTWYV\"\n",
    "polar_positions = [idx for idx, c in enumerate(gt_a4) if c in polar] # TODO\n",
    "nonpolar_positions = [idx for idx, c in enumerate(gt_a4) if c in non_polar]\n",
    "acidic_positions = [idx for idx, c in enumerate(gt_a4) if c in acidic]\n",
    "basic_positions = [idx for idx, c in enumerate(gt_a4) if c in basic]\n",
    "neutral_positions = [idx for idx, c in enumerate(gt_a4) if c in neutral]\n",
    "helix_positions = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 50, 51, 52, 53, 54, 55, 56, 57, 58, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
    "sheet_positions = [28, 29, 30, 31, 32, 39, 40, 41, 42, 43]\n",
    "loop_positions = [0, 1, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_positions = {}\n",
    "names = []\n",
    "values = []\n",
    "print(pf_rel_a4.shape)\n",
    "for name, pos in {\n",
    "    \"spyCas9 contact\": cas_positions,\n",
    "    \"non-contact\": non_cas_positions,\n",
    "    \"surface\": surface_positions,\n",
    "    \"core\": core_positions,\n",
    "    \"structured\": helix_positions + sheet_positions,\n",
    "    \"loop\": loop_positions,\n",
    "    \"acidic\": acidic_positions,\n",
    "    \"basic\": basic_positions,\n",
    "    \"neutral\": neutral_positions,\n",
    "    \"polar\": polar_positions,\n",
    "    \"non-polar\": nonpolar_positions,\n",
    "}.items():\n",
    "    items = []\n",
    "    positions = pos\n",
    "    for pos in positions:\n",
    "        update = list((pf_rel_a4.mean(axis=0)[pos, :20] * conversion_factor).sum(axis=1) - (pf_wt_a4.mean(axis=0)[:20] * conversion_factor).sum(axis=0))\n",
    "        update = [item for idx, item in enumerate(update)]\n",
    "        items += update\n",
    "    names.extend([name] * len(items))\n",
    "    values.extend(items)\n",
    "\n",
    "split_positions = dict(name=names, value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import violinplot\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "violinplot(x=\"name\", y=\"value\", width=1, data=split_positions, ax=ax, inner=\"quartiles\")\n",
    "\n",
    "count = 0\n",
    "for l in ax.lines:\n",
    "    if count % 3 == 1:\n",
    "        l.set_linestyle('-')\n",
    "        l.set_color('black')\n",
    "    else:\n",
    "        l.set_linestyle(\":\")\n",
    "        l.set_color('black')\n",
    "    count += 1\n",
    "\n",
    "plt.savefig(f\"{base_dir}/outputs/acriia4_activity_distribution.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation mean fluorescence + cell culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_culture = dict(\n",
    "    wt=(0.958145856666667, 0.55904086),\n",
    "    K18M=(0.82442277, 0.40304539),\n",
    "    G21Q=(0.80654383, 0.32298049),\n",
    "    S24K=(0.773889983333333, 0.375188933333333),\n",
    "    S24P=(0.706929726666667, 0.30560112),\n",
    "    N25G=(0.820051383333333, 0.376600463333333),\n",
    "    I31Q=(0.83000416, 0.386209923333333),\n",
    "    E40I=(0.731740993333333, 0.33765131),\n",
    "    E70T=(0.069560613333333, 0.035723183333333),\n",
    "    M77A=(0.174492683333333, 0.084132156666667)\n",
    ")\n",
    "\n",
    "kind = 0\n",
    "names = [\"wt\"]\n",
    "cc = [cell_culture[\"wt\"][kind]]\n",
    "pf_rel_a4_mean = (pf_rel_a4.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "pf_wt_a4_mean = (pf_wt_a4.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "value = [pf_wt_a4_mean]\n",
    "for name in cell_culture:\n",
    "    if name != \"wt\":\n",
    "        pos = int(name[1:-1]) - 1\n",
    "        aa = AA_CODE.index(name[-1])\n",
    "        val = pf_rel_a4_mean[pos, aa]\n",
    "        value.append(val)\n",
    "        cc.append(cell_culture[name][kind])\n",
    "        names.append(name)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(value, cc)\n",
    "\n",
    "for i, txt in enumerate(names):\n",
    "    ax.annotate(txt, (value[i], cc[i]))\n",
    "    \n",
    "plt.savefig(f\"{base_dir}/outputs/acriia4_fluorescence_vs_cell_culture.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation mean fluorescence to prior work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_activity_basgall = [0.027, 0.074, 0.015, 0.015, 0.084, 0.344, 0.845, 0.020, 0.000, 0.015, 0.113, 0.885, 0.983, 0.000, 0.595, 0.000, 0.432]\n",
    "activity_basgall = [-np.log(v + 1e-3) for v in drive_activity_basgall]\n",
    "names_basgall = [\"D14A\", \"D23R\", \"N36A\", \"D37A\", \"G38A\", \"N39A\", \"N39R\", \"E40A\", \"N48A\", \"D69A\", \"D69R\", \"E70A\", \"E70R\", \"E72A\", \"F73A\", \"D76A\", \"M77A\"]\n",
    "activity_dong = [1.067, 0.216, 0.043, 0.062, 0.056, 0.048, 0.038, 0.130, 0.022]\n",
    "names_dong = [\"N12T\", \"D14R\", \"D23R\", \"N36Y\", \"G38A\", \"N39R\", \"E40R\", \"D69R\", \"E70R\"]\n",
    "activity_dong = [np.log(v) for v in activity_dong]\n",
    "\n",
    "pred_log_basgall = [\n",
    "    pf_rel_a4_mean[int(name[1:-1]) - 1, AA_CODE.index(name[-1])]\n",
    "    for name in names_basgall\n",
    "]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].scatter(pred_log_basgall, activity_basgall)\n",
    "\n",
    "for i, txt in enumerate(names_basgall):\n",
    "    ax[0].annotate(txt, (pred_log_basgall[i], activity_basgall[i]))\n",
    "\n",
    "\n",
    "pred_log_dong = [\n",
    "    pf_rel_a4_mean[int(name[1:-1]) - 1, AA_CODE.index(name[-1])]\n",
    "    for name in names_dong\n",
    "]\n",
    "ax[1].scatter(pred_log_dong, activity_dong)\n",
    "\n",
    "for i, txt in enumerate(names_dong):\n",
    "    ax[1].annotate(txt, (pred_log_dong[i], activity_dong[i]))\n",
    "\n",
    "plt.savefig(f\"{base_dir}/outputs/correlation_prior_work.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R^2 for log-log fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2 Basgall et al.\", np.corrcoef(np.array(pred_log_basgall), np.array(activity_basgall))[0, 1] ** 2)\n",
    "print(\"R^2 Dong et al.\", np.corrcoef(np.array(pred_log_dong), np.array(activity_dong))[0, 1] ** 2)\n",
    "print(\"R Basgall et al.\", np.corrcoef(np.array(pred_log_basgall), np.array(activity_basgall))[0, 1])\n",
    "print(\"R Dong et al.\", np.corrcoef(np.array(pred_log_dong), np.array(activity_dong))[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation tolerance A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_rel_a5_mean = (pf_rel_a5.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "pf_wt_a5_mean = (pf_wt_a5.mean(axis=0) * conversion_factor).sum(axis=-1)\n",
    "for threshold in [0.9, 0.95, 1.0]:\n",
    "    print(threshold, (pf_rel_a5_mean >= pf_wt_a5_mean * threshold).sum() / pf_rel_a5_mean.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_heatmap(pf_rel_a5, pf_wt_a5, gt_a5, f\"{base_dir}/outputs/large-prediction-dotheatmap-A5-final.svg\", scale=4)\n",
    "square_heatmap(pf_rel_a5, pf_wt_a5, gt_a5, f\"{base_dir}/outputs/large-prediction-squareheatmap-A5-final.svg\", scale=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amino-acid type overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position-wise violin plots\n",
    "surface_positions = [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86, 87, 89, 92, 95, 96, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139]\n",
    "core_positions = [3, 7, 29, 32, 35, 36, 39, 50, 51, 53, 60, 62, 63, 80, 83, 84, 88, 90, 91, 93, 94, 97, 98, 101, 105, 116, 121, 125, 128, 131]\n",
    "polar = \"RNDCEQHKSTWY\"\n",
    "non_polar = \"AGILMFPV\"\n",
    "basic = \"RHK\"\n",
    "acidic = \"DE\"\n",
    "neutral = \"ANCQGILMFPSTWYV\"\n",
    "polar_positions = [idx for idx, c in enumerate(gt_a5) if c in polar]\n",
    "nonpolar_positions = [idx for idx, c in enumerate(gt_a5) if c in non_polar]\n",
    "acidic_positions = [idx for idx, c in enumerate(gt_a5) if c in acidic]\n",
    "basic_positions = [idx for idx, c in enumerate(gt_a5) if c in basic]\n",
    "neutral_positions = [idx for idx, c in enumerate(gt_a5) if c in neutral]\n",
    "helix_positions = [4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 135, 136, 137, 138]\n",
    "sheet_positions = [42, 43, 44, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63]\n",
    "loop_positions = [0, 1, 2, 3, 13, 14, 15, 16, 17, 18, 39, 40, 41, 45, 46, 47, 48, 49, 55, 56, 57, 58, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 109, 115, 116, 117, 131, 132, 133, 134, 139]\n",
    "idr_positions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "idr_2_positions = list(range(64, 79))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_positions = {}\n",
    "names = []\n",
    "values = []\n",
    "for name, pos in {\n",
    "    \"surface\": surface_positions,\n",
    "    \"core\": core_positions,\n",
    "    \"structured\": helix_positions + sheet_positions,\n",
    "    \"loop\": loop_positions,\n",
    "    \"IDR-NT\": idr_positions,\n",
    "    \"IDR-center\": idr_2_positions,\n",
    "    \"acidic\": acidic_positions,\n",
    "    \"basic\": basic_positions,\n",
    "    \"neutral\": neutral_positions,\n",
    "    \"polar\": polar_positions,\n",
    "    \"non-polar\": nonpolar_positions,\n",
    "}.items():\n",
    "    items = []\n",
    "    positions = pos\n",
    "    for pos in positions:\n",
    "        update = list(pf_rel_a5_mean[pos, :20] - pf_wt_a5_mean)\n",
    "        update = [item for idx, item in enumerate(update)]\n",
    "        items += update\n",
    "    names.extend([name] * len(items))\n",
    "    values.extend(items)\n",
    "\n",
    "split_positions = dict(name=names, value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import violinplot\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "violinplot(x=\"name\", y=\"value\", width=1, data=split_positions, ax=ax, inner=\"quartiles\")\n",
    "\n",
    "count = 0\n",
    "for l in ax.lines:\n",
    "    if count % 3 == 1:\n",
    "        l.set_linestyle('-')\n",
    "        l.set_color('black')\n",
    "    else:\n",
    "        l.set_linestyle(\":\")\n",
    "        l.set_color('black')\n",
    "    count += 1\n",
    "\n",
    "plt.savefig(f\"{base_dir}/outputs/acriia5_activity_distribution.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amino acid mutant correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(np.corrcoef(pf_rel_a4_mean.T), cmap=\"Reds\")\n",
    "ax.set_xticks(np.arange(21))\n",
    "ax.set_xticklabels(AA_CODE)\n",
    "ax.set_yticks(np.arange(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "plt.colorbar(cax)\n",
    "plt.savefig(f\"{base_dir}/outputs/aa_correlation_a4.svg\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(np.corrcoef(pf_rel_a5_mean.T), cmap=\"Reds\")\n",
    "ax.set_xticks(np.arange(21))\n",
    "ax.set_xticklabels(AA_CODE)\n",
    "ax.set_yticks(np.arange(21))\n",
    "ax.set_yticklabels(AA_CODE)\n",
    "plt.colorbar(cax)\n",
    "plt.savefig(f\"{base_dir}/outputs/aa_correlation_a5.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
